{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40245fc6",
   "metadata": {},
   "source": [
    "## Record-pair Linkage Predictive Modeling Program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec8156e",
   "metadata": {},
   "source": [
    "### Author: CDC's Data Science Upskilling (DSU) Team named, \"MYABC 4 PPRL\"\n",
    "### Membership: DSU 2021-2022 (Cohort 3)\n",
    "#### Team Project: Privacy Preserving Record Linkage (PPRL)\n",
    "\n",
    "\n",
    "Python Program Description: \n",
    "This NoteBook contains ## Two model performance improvement activities are in this file: \n",
    "1.) Feature selection\n",
    "2.) Parameter tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df91cba6",
   "metadata": {},
   "source": [
    "### Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e0ae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt  # works with seaborn etc to display plots created by seaborn etc\n",
    "from matplotlib import style # to make the output of matplotlib pretier (all charts then turned red)\n",
    "style.use(\"ggplot\")# used because I prefer blue color for my charts\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.express as plotExp\n",
    "import plotly.figure_factory as factory_fig\n",
    "import plotly.graph_objs as graphObj\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler # would handle outliers (data standardization)\n",
    "from sklearn.preprocessing import LabelEncoder # for transforming Categorical data to Numerical data\n",
    "\n",
    "#import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c9d366",
   "metadata": {},
   "outputs": [],
   "source": [
    "## So we could display our plots in a cell\n",
    "\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams ['figure.figsize']=10,8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e856d1d",
   "metadata": {},
   "source": [
    "Let's utilize the interactive shell of Jupyter to ensure we could print multiple outplut from a cell, thus all output would come through from Ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75173759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity=\"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bff85d6",
   "metadata": {},
   "source": [
    "#### Modify some of the Pandas printing capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b6694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, Pandas will display only 10 rows/cols\n",
    "\n",
    "# Globally set Max rows displayed in output to 20\n",
    "pd.set_option('display.max_rows', 30)\n",
    "\n",
    "# Globally set display for Pandas to always display all the columns\n",
    "#pd.set_option('display.line_width', 5000)\n",
    "pd.set_option('display.max_columns', None)# Settig to none makes display unlimited, better than putting a number\n",
    "\n",
    "# Globally set Max rows displayed in output to 20\n",
    "pd.set_option('display.max_rows', None)  # Great! No deprecation, many rows printed as wanted\n",
    "\n",
    "# Globally set decimal places Displayed in output to any number of choice, change it prn\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "# Globally set floatto avoid getting such values in\n",
    "#exponent notation, in correlation especially (Worked)\n",
    "pd.options.display.float_format = '{:20,.4f}'.format \n",
    "\n",
    "# Globally set max_colwidth display\n",
    "pd.options.display.max_colwidth = None # This removes any limit to num of col to be shown\n",
    "\n",
    "# Globally set display expand_frame_repr\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c4c3fb",
   "metadata": {},
   "source": [
    "#### Read the pickle file containing the comparison output to memory "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f508d24",
   "metadata": {},
   "source": [
    "**** Comment out other datasets while reading one that you are to work with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40c4620",
   "metadata": {},
   "outputs": [],
   "source": [
    "##This is the comparison output data where the blocking variable was firstORlastname\n",
    "pprl_DF2=pd.read_pickle('comparison_output_fln.pkl')# dubbed as \"firstORlastname\" dataset\n",
    "\n",
    "\n",
    "##This is the comparison output data where the blocking variable was firstname\n",
    "pprl_DF2=pd.read_pickle('comparison_output_fn.pkl') # dubbed as \"firstname\" dataset\n",
    "\n",
    "\n",
    "##This is the comparison output data where the blocking variable was lastname\n",
    "pprl_DF2=pd.read_pickle('comparison_output_ln.pkl')# dubbed as \"lastname\" dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366f64a9",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec95ea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprl_DF2.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dcb84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprl_DF2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb81b5c2",
   "metadata": {},
   "source": [
    "#### Rename columns as needed, using Dictionary data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3a6f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprl_DF2.rename(columns={'dob': 'dateOfBirth', 'firstname':'firstName','lasttname':'lastName'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b23217",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprl_DF2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400bf1b9",
   "metadata": {},
   "source": [
    "### Multiclass Classification Target Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9371b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove the binary target\n",
    "\n",
    "pprl_DF2.drop(\"true_links\",axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30438cad",
   "metadata": {},
   "source": [
    "### Compute Df rowwise mean, and round to 1 decimal place to permit float comparison down the road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1d8b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute Df rowwise mean, and round to 1 decimal place to permit float comparison down the road\n",
    "pprl_DF2['row_Means'] =pprl_DF2.mean(axis=1).round(1) # Round to permit comparison, based on exp with working wt mock data\n",
    "pprl_DF2['row_Means'].describe()\n",
    "pprl_DF2['row_Means'].head()\n",
    "print('============================')\n",
    "pprl_DF2.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f5b42e",
   "metadata": {},
   "source": [
    "#### Bin the row means and categorize them as matching classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6591d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### View distinct values in matched DF and their frequencies, and sort them by frequency\n",
    "\n",
    "pprl_DF2['row_Means'].value_counts().sort_values()\n",
    "\n",
    "pprl_DF2['matched']=pprl_DF2['row_Means']\n",
    "\n",
    "\n",
    "pprl_DF2['matched']=pd.cut(pprl_DF2.matched, bins=[\n",
    "    -0.001, 0.45, 0.75,2.0], labels=['no','mayBe','yes'])# small, medium, large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25385ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprl_DF2.drop('row_Means', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56595a8b",
   "metadata": {},
   "source": [
    "##### Create feature vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ec6e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "x =pprl_DF2.drop(\"matched\", axis=1)\n",
    "y =pprl_DF2.matched"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffab782",
   "metadata": {},
   "source": [
    "###### Transform categorical data into numerical data\n",
    "(only the target is categorical in the 3 cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395497f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encod=LabelEncoder()\n",
    "label_encod.fit(y)\n",
    "y=label_encod.transform(y)\n",
    "classes=label_encod.classes_\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51119cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8454921a",
   "metadata": {},
   "source": [
    "##### Import the modelling-related classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef1e42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imblearn # Required before importing the imblearn pipeline and SMOTE \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d18c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from numpy.random import RandomState\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report # useful for evaluating our models, \n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV, cross_val_score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import Pipeline as imbaPipe # The SMOTE class is in the imblearn package.\n",
    "from imblearn.pipeline import make_pipeline # For gridsearching SMOTE inside Grid\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE # SMOTE= synthetic minority oversampling technique\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score,roc_curve\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_fscore_support # For summary table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab58f883",
   "metadata": {},
   "source": [
    "### Split the dataset (Create train-test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240008e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split Data into training and test (you can split as desired, but 70:30% was used here) \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.3,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a54abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Check data shape after spliting, before scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c373a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the Output Dimensions\n",
    "# We can confirm the dimensions of the data are the same within test and train\n",
    "# The proportion should also be close to the test_size argument.\n",
    "\n",
    "\n",
    "x_train.shape\n",
    "x_test.shape\n",
    "y_train.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381ba06d",
   "metadata": {},
   "source": [
    "#### Now scale the training and testing features separately to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93585c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() # If StandardScaler is used, there could be negative numbers generated and some ML algs may not work well with -ve numbers\n",
    "\n",
    "# TO AVOID DATA LEAKAGE, SCALE EACH PART OF THE TRAINING DATA SEPARATELY\n",
    "x_train=scaler.fit_transform(x_train)\n",
    "x_test=scaler.transform(x_test)\n",
    "\n",
    "##### It is expected that scaling put all the trainign data in a range of 0 and 1 by now-- yes, achieved!\n",
    "\n",
    "x_train[:5]# Show me 5 records in Xtrain\n",
    "x_test[:5] # Show me 5 records in Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6113a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the necessary modeling packages for multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8518a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import pipeline# import the pipeline class\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from imblearn.pipeline import Pipeline as imbaPipe\n",
    "\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score, f1_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier # OVR\n",
    "from sklearn.multiclass import OneVsOneClassifier # OVO\n",
    "from sklearn import svm # Required with OVR\n",
    "from sklearn.linear_model import LogisticRegression# its multinomial parameter is ovr by default\n",
    "from sklearn.naive_bayes import MultinomialNB# its multinomial parameter is ovr by default\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "# Import the Pipeline API\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Import a data standaizer of your choice\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler  # To handle outliers etc\n",
    "from sklearn.preprocessing import LabelEncoder,     OneHotEncoder, MinMaxScaler, StandardScaler # aka ONEHOT: for transforming Cat features (X) to Numerical\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV, cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# import the needed module from scikit\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_fscore_support # For summary table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c42fdfa",
   "metadata": {},
   "source": [
    "#### Perform ML Experiments "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a7248e",
   "metadata": {},
   "source": [
    "#### Build multiple models\n",
    "***** Steps:\n",
    "\n",
    "1. First: Build baseline models\n",
    "2. Address class imbalance- using SMOTE (first in default mode with classifiers in their default modes as well)\n",
    "3. Perform hyperparameter tuning of classifiers and SMOTE to improve model performance\n",
    "4. Build more models\n",
    "5. Evaluate the models\n",
    "6. Identify the most generalizable model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d435b0c",
   "metadata": {},
   "source": [
    "### Feature Selection \n",
    "Carry out feature selection before data augmentation because the latter operation could influence the result of the former.\n",
    "\n",
    "Feature selection is a process of eliminating the less/non-predictive features from the data. The benefits of this process include dimension reduction, model performance improvement, and "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ac8109",
   "metadata": {},
   "source": [
    "#### Information Gain Analysis (Feature importances) with random forest (prior data augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566f6992",
   "metadata": {},
   "source": [
    "## ***** Add note on information gain analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7f01ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb20957c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rForestPipe_SK=Pipeline([(\"dataScaler\", scaler),('forest', RandomForestClassifier())])\n",
    "Forestmodel=rForestPipe_SK.steps[1][1].fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6590efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OfFeat_Importance=pd.DataFrame({'PPRL_ForLastname_Coef': x.columns, \n",
    "                                   \"Rforest Relative Importance\":Forestmodel.feature_importances_}\n",
    "                                 ).sort_values(\n",
    "                        \"Rforest Relative Importance\", ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "df_OfFeat_Importance.to_csv('PPRL_featImp_BVar_[FirstORlastname].csv')\n",
    "df_OfFeat_Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63452da",
   "metadata": {},
   "source": [
    "#### Plot feat importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104b92d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_Importance=Forestmodel.feature_importances_\n",
    "sorted_index=np.argsort(feat_Importance)\n",
    "#position=np.arange(sorted_index.shape)# output is a tuple:  array([0, 3, 2, 1], dtype=int64)\n",
    "position1=np.arange(sorted_index.shape[0])# we only need the item in index 0 of the tuple\n",
    " \n",
    "position2=np.arange(sorted_index.shape[0])+0.5 # add 0.5 else, it'll start at 0\n",
    "sorted_index=np.argsort(feat_Importance)\n",
    "position=np.arange(sorted_index.shape[0])+0.5\n",
    "fig=plt.figure(figsize=(12,6))\n",
    "#plt.subplot(1,2,1)\n",
    "plt.barh(position,feat_Importance[sorted_index])#, align=\"center\")\n",
    "plt.yticks(position,np.array(x.columns)[sorted_index])\n",
    "#plt.bar_label(plt.containers[0])\n",
    "plt.title(\"PPRL Feature Importance: BVar [FirstORlastname]\")\n",
    "#plt.savefig(\"PPRL_featImp_FirstORlastname.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5740b0d0",
   "metadata": {},
   "source": [
    "**** Set information gain threshold (IGT), and drop any feature not meeting the threshold\n",
    "Example: For the \"firstORlastname\" dataset, IGT was set to 0.1, without approximation), and the feature not meeting this threshold was dropped (as shown below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d237e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprl_DF2.drop('zipCode', axis=1, inplace=True)# based on feature importances result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132e0e7e",
   "metadata": {},
   "source": [
    "### Parameter Tuning for \"FirstORlastname\" dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4213a1bc",
   "metadata": {},
   "source": [
    "#### NBayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f579bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make an instance of the NBayes (Put all params at default)\n",
    "\n",
    "nBayes_Instance=MultinomialNB()\n",
    "## Obtain the parameters available inside NBayes\n",
    "\n",
    "#nBayes_Instance.get_params().keys()\n",
    "\n",
    "# Output: dict_keys(['alpha', 'class_prior', fit_prior'])\n",
    "\n",
    "\n",
    "crossVal = KFold(n_splits=3, random_state=2, shuffle=True)\n",
    "\n",
    "nBayesparam_gridTosearch={'alpha': [1,2,3,5,5,7,8,9,10]}\n",
    "\n",
    "grid_NBayes = GridSearchCV(nBayes_Instance,\n",
    "                         param_grid = [nBayesparam_gridTosearch],\n",
    "                         cv=crossVal,\n",
    "                         scoring='roc_auc',\n",
    "                         return_train_score=True,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=True)\n",
    "\n",
    "grid_NBayes.fit(x_train, y_train)\n",
    "NBbestimator = grid_NBayes.best_estimator_\n",
    "NBbestimator\n",
    "ypred = NBbestimator.predict(x_test)# predicted_Classes\n",
    "print(ypred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a9b6dc",
   "metadata": {},
   "source": [
    "*****Utilize the obtained result in searching for the best k value in the k_neighbor parameter of SMOTE for NBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3dca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k in range(1,11): # 10 k values\n",
    "\n",
    "    smDefauNbayes_def= imbaPipe([('smote', SMOTE(sampling_strategy =\"auto\",\n",
    "                                            k_neighbors=k, random_state=40)),\n",
    "                                           (\"dataScaler\", scaler), \n",
    "                                 (\"naive\", MultinomialNB(alpha=1))])\n",
    "\n",
    "    pipe1=smDefauNbayes_def\n",
    "         #### RESAMPLE THE DATA NOW, SINCE SPLITED INTO FOLDS \n",
    "#     x_train_oversampled, y_train_oversampled = pipe1.steps[0][1].fit_resample(\n",
    "#                                                                      x_train, y_train)\n",
    "    \n",
    "    x_train_oversampled=x_train\n",
    "    y_train_oversampled =y_train  \n",
    "    \n",
    "    nbayes_model=pipe1.fit(x_train_oversampled,y_train_oversampled)## see lecture 6.7 from Andrew ng on log reg for multi class ovr\n",
    "    \n",
    "    #    nbayes_model=pipe1.steps[2][1].fit(x_train_oversampled,y_train_oversampled)## see lecture 6.7 from Andrew ng on log reg for multi class ovr\n",
    "\n",
    "    predicted_Values=nbayes_model.predict(x_test)\n",
    "    train_testScore=(nbayes_model.score(x_train_oversampled,\n",
    "                                        y_train_oversampled),\n",
    "                                     nbayes_model.score(x_test,y_test))\n",
    "    print('> k=%d', (k, train_testScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9d106e",
   "metadata": {},
   "source": [
    "##### Use the output to create full Imblearn Pipeline for Naive Bayes in each modeling file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b38b0db",
   "metadata": {},
   "source": [
    "#### Random Forest (an estimator for OVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a63f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make an instance of the logisitic regression (Put all params at default, hence, left empty)\n",
    "randForest_Instance = RandomForestClassifier()## or pass .steps[1][1]\n",
    "## Create a Dict of param names and list their values as available in Log Reg Scikit\n",
    "   \n",
    "#RandForest_Instance.get_params().keys()\n",
    "\n",
    "## Number of trees in the forest. We're using list comprehension here\n",
    "n_estimators=[int(x) for x in np.linspace(start=2, stop=5, num=12)] #  i.e 12 of these, starting from 10, up to 80\n",
    "\n",
    "## number of features to considere at every node split \n",
    "max_features= ['auto', 'sqrt']\n",
    "\n",
    "## Maximum of levels in each tree\n",
    "max_depth= [4, 8, 12, 25]\n",
    "\n",
    "random_state= [1,4, 20, 42]\n",
    "\n",
    "\n",
    "# Minimum number lof samples required to split a node\n",
    "min_samples_split= [2, 5,10]\n",
    "\n",
    "## Minimum number of samples required at each leaf node\n",
    "min_samples_leaf= [5, 10, 20, 25]\n",
    "\n",
    "bootstrap= [True, False]\n",
    "\n",
    "resampler = SMOTE(sampling_strategy=\"auto\", random_state=42,k_neighbors=5)\n",
    "\n",
    "           \n",
    "### NOW CREATE A DICT OF THE PARAMS IN THE PARAMS GRID            \n",
    "RFparam_gridTosearch= {'n_estimators': n_estimators, \n",
    "            'max_features': max_features,\n",
    "             'max_depth' : max_depth,\n",
    "              'random_state' : random_state,\n",
    "            'min_samples_split' : min_samples_split,\n",
    "             'min_samples_leaf' : min_samples_leaf,\n",
    "            'bootstrap': bootstrap}\n",
    "\n",
    "################\n",
    "print('Let us see what we have inside the gridsearch algorithm', RFparam_gridTosearch)          \n",
    "\n",
    "#cv=2,\n",
    "\n",
    "\n",
    "gridSch_ForRandForest =GridSearchCV(estimator=randForest_Instance,\n",
    "                                    param_grid = RFparam_gridTosearch, cv=3,\n",
    "                     verbose=2,n_jobs=-1)\n",
    "\n",
    "\n",
    "##### Now fit the training set on Grid\n",
    "\n",
    "BestClf_fromGrid_resultRF = gridSch_ForRandForest.fit(x_train,y_train)\n",
    "\n",
    "print(\"============== get best params- is it not the same as get best estimator_\"  )\n",
    "BestClf_fromGrid_resultRF.best_params_\n",
    "\n",
    "#output of\n",
    "# get BestClf_fromGrid_resultRF.best_params_ \n",
    "                                                # {'bootstrap': False, 'max_depth': 25, \n",
    "#                                             'max_features': 'auto', 'min_samples_leaf': 5, \n",
    "#                                             'min_samples_split': 2, 'n_estimators': 35}\n",
    "\n",
    "\n",
    "print('get BestClf_fromGrid_resultRF.best_params_', BestClf_fromGrid_resultRF.best_params_)\n",
    "\n",
    "BestClf_fromGrid_resultRF.best_estimator_\n",
    "\n",
    "\n",
    "# Check accuracy of the GridSeatch model\n",
    "print('BestClf_fromGrid_resultRF.score', BestClf_fromGrid_resultRF.score(x_test,y_test))\n",
    "\n",
    "print(\"new formating way, see if the printing works\")\n",
    "print(f'Train Accu_RForest_WtGridSch - : {BestClf_fromGrid_resultRF.score(x_train,y_train):.3f}')\n",
    "print(f'TestAccu_RForest_WtGridSch - : {BestClf_fromGrid_resultRF.score(x_test,y_test):.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8af29a",
   "metadata": {},
   "source": [
    "*****Utilize the obtained result in searching for the best k value in the k_neighbor parameter of SMOTE for OVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2339f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1,11): # 10 k values\n",
    "    smOVRrfPipe_def= imbaPipe([('smote', SMOTE(sampling_strategy =\"auto\",\n",
    "                                        k_neighbors=k, random_state=40)),\n",
    "                                    (\"dataScaler\", scaler),\n",
    "                               ('ovrForest', OneVsRestClassifier(RandomForestClassifier(\n",
    "                                   bootstrap =False,max_depth=25,min_samples_leaf= 5,\n",
    "                                    min_samples_split=2,n_estimators=5,random_state= 42)))])  \n",
    "    pipe2=smOVRrfPipe_def  \n",
    "    x_train_oversampled=x_train\n",
    "    y_train_oversampled =y_train  \n",
    "    \n",
    "    ovr_model=pipe2.fit(x_train_oversampled,y_train_oversampled)## see lecture 6.7 from Andrew ng on log reg for multi class ovr\n",
    "\n",
    "    \n",
    "    predicted_Values=ovr_model.predict(x_test)\n",
    "    train_testScore=(ovr_model.score(x_train_oversampled,\n",
    "                    y_train_oversampled),\n",
    "                     ovr_model.score(x_test,y_test))\n",
    "    print('> k=%d', (k, train_testScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa41786f",
   "metadata": {},
   "source": [
    "##### Use the output to create full Imblearn Pipeline for OneVersusRest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ff5d3c",
   "metadata": {},
   "source": [
    "#### Logistic Regression Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d2c7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=LogisticRegression()\n",
    "crossVal = KFold(n_splits=3, random_state=2, shuffle=True)\n",
    "\n",
    "LRegparam_gridTosearch = {'penalty': ['l2'], 'multi_class': ['auto','ovr'],\n",
    "              'solver': ['newton-cg','lbfgs', 'sag', 'saga'], \n",
    "                          'C': [0.001,0.01,0.1,1,10,100,1000]}\n",
    "\n",
    "grid_Lreg = GridSearchCV(classifier,param_grid = LRegparam_gridTosearch,\n",
    "                         cv=crossVal,\n",
    "                         scoring='accuracy',\n",
    "                         return_train_score=True,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=True\n",
    "                        )\n",
    "grid_Lreg.fit(x_train, y_train)\n",
    "bestimator = grid_Lreg.best_estimator_\n",
    "bestimator\n",
    "ypred = bestimator.predict(x_test)# predicted_Classes\n",
    "print(ypred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dc62d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1,11): # 10 k values\n",
    "    smLRegPipe_def= imbaPipe([('smote', SMOTE(sampling_strategy =\"auto\", \n",
    "                                              k_neighbors=k, random_state=40)),\n",
    "                                           (\"dataScaler\", scaler),\n",
    "                              (\"lreg\", LogisticRegression(C=1000, solver='newton-cg'))])\n",
    "    pipe4=smLRegPipe_def\n",
    "    x_train_oversampled=x_train\n",
    "    y_train_oversampled =y_train  \n",
    "    \n",
    "    LReg_model=pipe4.fit(x_train_oversampled,y_train_oversampled)## see lecture 6.7 from Andrew ng on log reg for multi class ovr\n",
    "\n",
    "    \n",
    "    predicted_Values=LReg_model.predict(x_test)\n",
    "    train_testScore=(LReg_model.score(x_train_oversampled,y_train_oversampled),\n",
    "                     LReg_model.score(x_test,y_test))\n",
    "    print('> k=%d', (k, train_testScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1682b575",
   "metadata": {},
   "source": [
    "##### Use the output to create full Imblearn Pipeline for Naive Bayes in each modeling file for LReg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47710194",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done with feature selection and parameter tuning for firstORlastname [fln] data!=====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d705fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
